{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 25693, 'cuisine': 'southern_us', 'ingredients': ['plain flour', 'ground pepper', 'salt', 'tomatoes', 'ground black pepper', 'thyme', 'eggs', 'green tomatoes', 'yellow corn meal', 'milk', 'vegetable oil']}\n"
     ]
    }
   ],
   "source": [
    "print(recipes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bad_ingr = list(filter(lambda x: dictionary.dfs[x] > 3500 and dictionary.dfs[x] < 3, dictionary.dfs.keys()))\n",
    "dictionary.filter_tokens(list_bad_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 7s, sys: 3.32 s, total: 17min 10s\n",
      "Wall time: 17min 13s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "%time lda = models.ldamodel.LdaModel(corpus, num_topics=20, passes=40, id2word=dictionary, alpha=0.5, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182.9532765470079"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(-lda.log_perplexity(list(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosha/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row(pre_row):\n",
    "    res = []\n",
    "    for i in range(20):\n",
    "        res.append(0)\n",
    "        for obj in pre_row:\n",
    "            if obj[0] == i:\n",
    "                res[i] = obj[1]\n",
    "                break\n",
    "    return res  \n",
    "\n",
    "\n",
    "x_data  = lda.get_document_topics(corpus)\n",
    "x_data = list(map(lambda x: create_row(x), x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = list(map(lambda x: x['cuisine'], recipes))\n",
    "dict_l = dict()\n",
    "i = 0\n",
    "for label in x_label:\n",
    "    if not label in dict_l.keys():\n",
    "        dict_l[label] = i\n",
    "        i += 1\n",
    "x_label = list(map(lambda x: dict_l[x], x_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "a[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.24      0.31       147\n",
      "          1       0.35      0.70      0.46       499\n",
      "          2       0.48      0.13      0.20        95\n",
      "          3       0.73      0.84      0.78       368\n",
      "          4       0.50      0.06      0.10        52\n",
      "          5       0.00      0.00      0.00       129\n",
      "          6       0.62      0.83      0.71       918\n",
      "          7       0.81      0.88      0.84       780\n",
      "          8       0.42      0.86      0.57       335\n",
      "          9       0.62      0.05      0.09       101\n",
      "         10       0.54      0.24      0.33       181\n",
      "         11       0.32      0.07      0.12        99\n",
      "         12       0.45      0.34      0.39       208\n",
      "         13       0.25      0.08      0.12        51\n",
      "         14       0.35      0.11      0.17       300\n",
      "         15       0.39      0.10      0.16       170\n",
      "         16       0.00      0.00      0.00        91\n",
      "         17       0.00      0.00      0.00       113\n",
      "         18       0.48      0.31      0.37        95\n",
      "         19       1.00      0.02      0.05        42\n",
      "\n",
      "avg / total       0.52      0.56      0.50      4774\n",
      "\n",
      "CPU times: user 13.1 s, sys: 60 ms, total: 13.1 s\n",
      "Wall time: 14.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosha/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(C=100, penalty='l2', dual=False)\n",
    "clf.fit(x_data[:35000], x_label[:35000])\n",
    "print(metrics.classification_report(x_label[35000:], clf.predict(x_data[35000:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('lda_20')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
